{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time there was a little girl who everyone liked a lot, but most of all her grandmother. She could give this child anything. Once she gave her a little red hat, which suited her so well that she never wanted to wear anything else. She was therefore called Little Red Riding Hood.\n",
      "One day her mother said to her \"The Little Red Riding Hood, here's a piece of freshly baked cake and a bottle of wine. Take them to your grandmother, she's a little sick and that would do her good. Go before it gets too hot. Go carefully and do not leave the road, because then you can fall and smash the bottle. When you enter her room, do not forget to say good morning, before you run around every corner.\"\n",
      "\"I should be careful,\" Little Red Riding Hood said to her mother and left.\n",
      "Grandma lived out in the woods far from the village where Little Red Riding Hood lived. Just as Little Red Riding Hood entered the forest, a wolf met her. Little Red Riding Hood did not know what a strange figure he was and was not afraid of him at all.\n",
      "\"Good day, little Little Red Riding Hood, how are you my little friend,\" he said.\n",
      "\"Thank you, I'm fine,\" Little Red Riding Hood replied.\n",
      "\"Where are you going to go so early?\"\n",
      "\"To my grandmother.\"\n",
      "\"What do you have in the basket?\" Asked the wolf.\n",
      "\"Cake and wine. Yesterday was baking day and my poor sick grandmother is going to get something good so she can get better.\" \n"
     ]
    }
   ],
   "source": [
    "!head ./data/example/raw/src-train-sv.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En gång för länge sedan fanns det en liten flicka, som alla tyckte mycket om, men mest av alla hennes mormor. Hon skulle kunna ge detta barn vad som helst. En gång gav hon henne en liten röd luva, som passade henne så bra att hon aldrig ville ha på sig något annat. Hon kallades därför för Rödluvan.\n",
      "En dag sa hennes mor till henne \"Kom Rödluvan, här är en bit av den nybakade kakan och en flaska vin. Tag med dem till din mormor, hon är lite sjuk och det skulle göra henne gott. Gå innan det blir för varmt. Gå försiktigt och lämna inte vägen, för då kan du ramla och slå sönder flaskan. När du kommer in i hennes rum, skall du inte glömma att säga god morgon, innan du springer runt i varje hörn.\"\n",
      "\"Jag skall vara försiktig\", sa Rödluvan till sin mamma och gav sig iväg.\n",
      "Mormor bodde ute i skogen långt från byn där Rödluvan bodde. Just när Rödluvan gick in i skogen mötte en varg henne. Rödluvan visste inte vad det var för en konstig figur och blev inte alls rädd för honom.\n",
      "\"God dag, lilla Rödluvan, hur mår du min lilla vän\", sa han.\n",
      "\"Tack, jag mår bra\", svarade Rödluvan.\n",
      "\"Vart skall du ta vägen så tidigt?\"\"\n",
      "\"Till min mormor.\"\n",
      "\"Vad har du i korgen?\", frågade vargen.\n",
      "\"Kaka och vin. Igår var det bak-dag och min stackars sjuka mormor skall få något gott så att hon blir bättre.\"\n"
     ]
    }
   ],
   "source": [
    "!head ./data/example/raw/tgt-train-sv.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('')!=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done datasets preparation.\n"
     ]
    }
   ],
   "source": [
    "!python prepare_datasets.py --train_source=/workspace/parallel/out/OpusAll_en.txt --train_target=/workspace/parallel/out/OpusAll_sv.txt --val_source=/workspace/parallel/prep/val/WikiSource.en-sv.en --val_target=/workspace/parallel/prep/val/WikiSource.en-sv.sv --save_data_dir=/workspace/parallel/out/HFout/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5 6 7 8 9 6 10 11 12 13 14 6 15 16 17 18 19 20 21 22 23 24 25 26 27 4 28 29 20 6 10 30 31 32 33 20 34 35 36 28 37 38 39 40 41 42 22 9 43 44 45 46 47 48\t2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 15 22 23 24 25 26 27 28 29 30 14 31 4 5 32 33 34 11 12 35 36 14 37 34 38 39 40 33 41 42 43 44 45 46 47 24 48 49 6 50\t4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 15 22 23 24 25 26 27 28 29 30 14 31 4 5 32 33 34 11 12 35 36 14 37 34 38 39 40 33 41 42 43 44 45 46 47 24 48 49 6 50 3\n",
      "49 50 20 51 52 39 20 53 45 46 47 54 55 6 56 18 57 58 59 60 6 61 18 62 63 64 39 65 66 67 6 10 68 60 36 69 70 20 71 72 73 74 75 76 77 72 78 60 70 79 80 81 82 83 84 85 86 87 60 88 81 89 90 85 91 20 92 70 79 93 39 94 95 96 73 85 97 98 99 100\t2 4 51 52 22 53 54 34 55 56 57 58 11 59 21 60 61 62 63 11 64 65 66 67 68 54 69 70 33 58 71 72 63 10 25 73 34 74 75 76 10 77 6 78 75 79 63 80 81 82 6 83 84 85 86 63 87 88 89 90 85 91 92 93 22 94 95 85 81 96 40 97 98 99 76 85 100 101 93 102 103\t4 51 52 22 53 54 34 55 56 57 58 11 59 21 60 61 62 63 11 64 65 66 67 68 54 69 70 33 58 71 72 63 10 25 73 34 74 75 76 10 77 6 78 75 79 63 80 81 82 6 83 84 85 86 63 87 88 89 90 85 91 92 93 22 94 95 85 81 96 40 97 98 99 76 85 100 101 93 102 103 3\n",
      "101 102 103 104 45 46 47 105 52 39 20 51 60 106\t2 104 95 105 106 52 107 54 108 109 63 32 45 110\t104 95 105 106 52 107 54 108 109 63 32 45 110 3\n",
      "107 108 109 110 81 111 112 113 81 114 115 45 46 47 105 116 117 118 45 46 47 105 119 81 120 6 121 122 123 45 46 47 105 124 79 125 126 6 127 128 129 9 60 9 79 130 18 131 132 133\t2 111 112 113 93 114 115 116 117 118 107 119 120 121 107 122 92 93 114 123 11 124 125 107 126 81 30 10 127 6 11 128 129 63 130 81 131 132 6 133\t111 112 113 93 114 115 116 117 118 107 119 120 121 107 122 92 93 114 123 11 124 125 107 126 81 30 10 127 6 11 128 129 63 130 81 131 132 6 133 3\n",
      "134 135 10 45 46 47 54 136 137 85 138 10 139 129 140\t2 134 135 136 56 137 138 85 139 136 140 52 141\t134 135 136 56 137 138 85 139 136 140 52 141 3\n",
      "141 142 143 144 45 46 47 105 145\t2 142 143 138 144 145 50\t142 143 138 144 145 50 3\n",
      "146 137 85 147 39 148 34 149\t2 146 95 85 147 148 38 149\t146 95 85 147 148 38 149 3\n",
      "150 138 151\t2 150 139 151\t150 139 151 3\n",
      "152 70 85 153 110 81 154 155 81 156\t2 152 153 85 93 154 155 156\t152 153 85 93 154 155 156 3\n",
      "157 60 62 158 9 159 50 60 138 160 68 161 162 147 39 163 164 95 34 28 86 163 165\t2 157 63 65 158 127 10 159 63 139 160 161 162 95 163 46 164 38 40 33 77 165\t157 63 65 158 127 10 159 63 139 160 161 162 95 163 46 164 38 40 33 77 165 3\n"
     ]
    }
   ],
   "source": [
    "!head /workspace/parallel/out/HFout/indexed-train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t<PAD>\t0\n",
      "1\t<UNK>\t0\n",
      "2\t<StartSent>\t0\n",
      "3\t<EndSent>\t0\n",
      "4\tOnce\t3\n",
      "5\tupon\t1\n",
      "6\ta\t31\n",
      "7\ttime\t1\n",
      "8\tthere\t1\n",
      "9\twas\t23\n"
     ]
    }
   ],
   "source": [
    "!head /workspace/parallel/out/HFout/vocabulary-source.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531 ./data/example/processed/vocabulary-source.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l /workspace/parallel/out/HFout/vocabulary-source.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553 ./data/example/processed/vocabulary-target.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l /workspace/parallel/out/HFout/vocabulary-target.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t<PAD>\t0\n",
      "1\t<UNK>\t0\n",
      "2\t<StartSent>\t0\n",
      "3\t<EndSent>\t0\n",
      "4\tEn\t4\n",
      "5\tgång\t4\n",
      "6\tför\t15\n",
      "7\tlänge\t2\n",
      "8\tsedan\t3\n",
      "9\tfanns\t1\n"
     ]
    }
   ],
   "source": [
    "!head /workspace/parallel/out/HFout/vocabulary-target.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 5 6 7 8 9 6 10 11 12 13 14 6 15 16 17 18 19 20 21 22 23 24 25 26 27 4 28 29 20 6 10 30 31 32 33 20 34 35 36 28 37 38 39 40 41 42 22 9 43 44 45 46 47 48\t2 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 15 22 23 24 25 26 27 28 29 30 14 31 4 5 32 33 34 11 12 35 36 14 37 34 38 39 40 33 41 42 43 44 45 46 47 24 48 49 6 50\t4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 15 22 23 24 25 26 27 28 29 30 14 31 4 5 32 33 34 11 12 35 36 14 37 34 38 39 40 33 41 42 43 44 45 46 47 24 48 49 6 50 3\n",
      "49 50 20 51 52 39 20 53 45 46 47 54 55 6 56 18 57 58 59 60 6 61 18 62 63 64 39 65 66 67 6 10 68 60 36 69 70 20 71 72 73 74 75 76 77 72 78 60 70 79 80 81 82 83 84 85 86 87 60 88 81 89 90 85 91 20 92 70 79 93 39 94 95 96 73 85 97 98 99 100\t2 4 51 52 22 53 54 34 55 56 57 58 11 59 21 60 61 62 63 11 64 65 66 67 68 54 69 70 33 58 71 72 63 10 25 73 34 74 75 76 10 77 6 78 75 79 63 80 81 82 6 83 84 85 86 63 87 88 89 90 85 91 92 93 22 94 95 85 81 96 40 97 98 99 76 85 100 101 93 102 103\t4 51 52 22 53 54 34 55 56 57 58 11 59 21 60 61 62 63 11 64 65 66 67 68 54 69 70 33 58 71 72 63 10 25 73 34 74 75 76 10 77 6 78 75 79 63 80 81 82 6 83 84 85 86 63 87 88 89 90 85 91 92 93 22 94 95 85 81 96 40 97 98 99 76 85 100 101 93 102 103 3\n",
      "101 102 103 104 45 46 47 105 52 39 20 51 60 106\t2 104 95 105 106 52 107 54 108 109 63 32 45 110\t104 95 105 106 52 107 54 108 109 63 32 45 110 3\n",
      "107 108 109 110 81 111 112 113 81 114 115 45 46 47 105 116 117 118 45 46 47 105 119 81 120 6 121 122 123 45 46 47 105 124 79 125 126 6 127 128 129 9 60 9 79 130 18 131 132 133\t2 111 112 113 93 114 115 116 117 118 107 119 120 121 107 122 92 93 114 123 11 124 125 107 126 81 30 10 127 6 11 128 129 63 130 81 131 132 6 133\t111 112 113 93 114 115 116 117 118 107 119 120 121 107 122 92 93 114 123 11 124 125 107 126 81 30 10 127 6 11 128 129 63 130 81 131 132 6 133 3\n",
      "134 135 10 45 46 47 54 136 137 85 138 10 139 129 140\t2 134 135 136 56 137 138 85 139 136 140 52 141\t134 135 136 56 137 138 85 139 136 140 52 141 3\n",
      "141 142 143 144 45 46 47 105 145\t2 142 143 138 144 145 50\t142 143 138 144 145 50 3\n",
      "146 137 85 147 39 148 34 149\t2 146 95 85 147 148 38 149\t146 95 85 147 148 38 149 3\n",
      "150 138 151\t2 150 139 151\t150 139 151 3\n",
      "152 70 85 153 110 81 154 155 81 156\t2 152 153 85 93 154 155 156\t152 153 85 93 154 155 156 3\n",
      "157 60 62 158 9 159 50 60 138 160 68 161 162 147 39 163 164 95 34 28 86 163 165\t2 157 63 65 158 127 10 159 63 139 160 161 162 95 163 46 164 38 40 33 77 165\t157 63 65 158 127 10 159 63 139 160 161 162 95 163 46 164 38 40 33 77 165 3\n"
     ]
    }
   ],
   "source": [
    "!head /workspace/parallel/out/HFout/indexed-train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab not none 55 59 59\n",
      "vocab not none 80 81 81\n",
      "vocab not none 14 14 14\n",
      "vocab not none 50 40 40\n",
      "vocab not none 15 13 13\n",
      "vocab not none 9 7 7\n",
      "vocab not none 8 8 8\n",
      "vocab not none 3 4 4\n",
      "vocab not none 10 8 8\n",
      "vocab not none 23 22 22\n",
      "vocab not none 8 7 7\n",
      "vocab not none 25 23 23\n",
      "vocab not none 76 74 74\n",
      "vocab not none 96 91 91\n",
      "vocab not none 13 14 14\n",
      "vocab not none 5 5 5\n",
      "vocab not none 14 13 13\n",
      "vocab not none 18 20 20\n",
      "vocab not none 43 44 44\n",
      "vocab not none 37 37 37\n",
      "vocab not none 31 30 30\n",
      "vocab not none 37 35 35\n",
      "vocab not none 8 9 9\n",
      "vocab not none 11 10 10\n",
      "vocab not none 9 10 10\n",
      "vocab not none 7 8 8\n",
      "vocab not none 7 8 8\n",
      "vocab not none 6 7 7\n",
      "vocab not none 8 9 9\n",
      "vocab not none 7 9 9\n",
      "vocab not none 23 19 19\n",
      "vocab not none 51 47 47\n",
      "vocab not none 44 39 39\n",
      "vocab not none 47 42 42\n",
      "vocab not none 38 32 32\n",
      "vocab not none 62 53 53\n",
      "vocab not none 68 55 55\n",
      "vocab not none 102 95 95\n",
      "vocab not none 18 18 18\n",
      "vocab not none 26 24 24\n",
      "vocab not none 118 95 95\n",
      "vocab not none 42 38 38\n",
      "vocab not none 20 17 17\n"
     ]
    }
   ],
   "source": [
    "from os.path import dirname, abspath, join, exists\n",
    "from os import makedirs\n",
    "from dictionaries import START_TOKEN, END_TOKEN\n",
    "UNK_INDEX = 1\n",
    "vocabulary_size=531\n",
    "unknownify = lambda index: index if index < vocabulary_size else UNK_INDEX\n",
    "data=[]\n",
    "limit=128\n",
    "with open(join('./data/example/processed/', f'indexed-train.txt')) as file:\n",
    "    for line in file:\n",
    "        sources, inputs, targets = line.strip().split('\\t')\n",
    "        \n",
    "        if vocabulary_size is not None:\n",
    "            indexed_sources = [unknownify(int(index)) for index in sources.strip().split(' ')]\n",
    "            indexed_inputs = [unknownify(int(index)) for index in inputs.strip().split(' ')]\n",
    "            indexed_targets = [unknownify(int(index)) for index in targets.strip().split(' ')]\n",
    "            print(\"vocab not none\",len(indexed_sources), len(indexed_inputs), len(indexed_targets))\n",
    "        else:\n",
    "            indexed_sources = [int(index) for index in sources.strip().split(' ')]\n",
    "            indexed_inputs = [int(index) for index in inputs.strip().split(' ')]\n",
    "            indexed_targets = [int(index) for index in targets.strip().split(' ')]\n",
    "            print(\"vocab none\",len(indexed_sources), len(indexed_inputs), len(indexed_targets))\n",
    "        data.append((indexed_sources, indexed_inputs, indexed_targets))\n",
    "        if limit is not None and len(data) >= limit:\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
